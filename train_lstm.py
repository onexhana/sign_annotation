import os
import json
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import torch.nn.utils.rnn as rnn_utils
from collections import Counter
import re

# âœ… 1. Dataset ì •ì˜
class SignLanguageDataset(Dataset):
    def __init__(self, data_dir, label_map_path=None, min_samples=1):
        self.samples = []
        self.labels = []

        # ë¼ë²¨ ë§¤í•‘ ë¡œë“œ
        if label_map_path:
            with open(label_map_path, 'r', encoding='utf-8') as f:
                self.label_mapping = json.load(f)
        else:
            self.label_mapping = {}

        # íŒŒì¼ íƒìƒ‰ ë° ë¼ë²¨ ì •ì œ
        for file in os.listdir(data_dir):
            if not file.endswith('.npy'):
                continue

            # âœ… â‘  chunk ì œê±°
            filename_no_ext = file.replace('.npy', '')
            label_with_chunk = re.sub(r'_chunk\d+$', '', filename_no_ext)

            # âœ… â‘¡ ëŒ€í‘œê°’ ì¶”ì¶œ (ì‰¼í‘œë¡œ ë¬¶ì¸ ì²« ë‹¨ì–´)
            representative_label = label_with_chunk.split(',')[0]

            # âœ… â‘¢ ë§¤í•‘ ì ìš©
            mapped_label = self.label_mapping.get(label_with_chunk, representative_label)

            filepath = os.path.join(data_dir, file)
            self.samples.append(filepath)
            self.labels.append(mapped_label)

        # âœ… ë¼ë²¨ë³„ ê°œìˆ˜ ì¶œë ¥
        counts = Counter(self.labels)
        print("\U0001f50d ë¼ë²¨ë³„ ìƒ˜í”Œ ìˆ˜:")
        for label, count in counts.items():
            print(f"{label}: {count}")

        # âœ… ìƒ˜í”Œ ìˆ˜ ê¸°ì¤€ í•„í„°ë§
        filtered = [(x, y) for x, y in zip(self.samples, self.labels) if counts[y] >= min_samples]

        if not filtered:
            raise ValueError(f"âŒ ìœ íš¨í•œ í•™ìŠµ ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤. min_samples={min_samples} ê¸°ì¤€ì„ ë‚®ì¶”ì„¸ìš”.")

        self.samples = [x for x, _ in filtered]
        self.labels = [y for _, y in filtered]

        self.label2idx = {label: idx for idx, label in enumerate(sorted(set(self.labels)))}
        self.idx2label = {idx: label for label, idx in self.label2idx.items()}

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        data = np.load(self.samples[idx])
        label = self.label2idx[self.labels[idx]]
        return torch.tensor(data, dtype=torch.float32), torch.tensor(label)

# âœ… 2. Collate í•¨ìˆ˜
def collate_fn(batch):
    sequences, labels = zip(*batch)
    padded = rnn_utils.pad_sequence(sequences, batch_first=True)
    return padded, torch.tensor(labels)

# âœ… 3. LSTM ëª¨ë¸ ì •ì˜
class SignLSTM(nn.Module):
    def __init__(self, input_size, hidden_size, num_classes):
        super(SignLSTM, self).__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)
        self.fc = nn.Linear(hidden_size, num_classes)

    def forward(self, x):
        _, (hn, _) = self.lstm(x)
        return self.fc(hn.squeeze(0))

# âœ… 4. í•™ìŠµ ì‹¤í–‰
if __name__ == '__main__':
    data_dir = 'processed_sequences'
    label_map_path = 'label_mapping.json'

    dataset = SignLanguageDataset(data_dir, label_map_path=label_map_path, min_samples=1)
    dataloader = DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)

    input_size = 225
    hidden_size = 128
    num_classes = len(dataset.label2idx)

    model = SignLSTM(input_size, hidden_size, num_classes)
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

    print(f"\n\U0001f9e0 í•™ìŠµ ì‹œì‘: ì´ {len(dataset)}ê°œ ìƒ˜í”Œ, {num_classes}ê°œ í´ë˜ìŠ¤\n")

    for epoch in range(150):
        total_loss = 0
        for x_batch, y_batch in dataloader:
            output = model(x_batch)
            loss = criterion(output, y_batch)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"[Epoch {epoch+1:03d}] Loss: {total_loss:.4f}")

    torch.save(model.state_dict(), 'sign_lstm.pth')
    print("\nâœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: sign_lstm.pth")
    print("ğŸ“Œ ë¼ë²¨ ì¸ë±ìŠ¤ ë§¤í•‘:", dataset.label2idx)
